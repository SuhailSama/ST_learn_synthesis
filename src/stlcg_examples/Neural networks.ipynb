{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network examples\n",
    "This jupyter notebook was used to run the neural network examples, and used to produce the plots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import stlcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory /storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/examples\n"
     ]
    }
   ],
   "source": [
    "import matplotlib \n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "current_dir = os.getcwd()\n",
    "print('current directory', current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n",
    "# for Palatino and other serif fonts use:\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Palatino\"],\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bump example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating bump data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 24\n",
    "np.random.seed(1)\n",
    "x = np.arange(-2,2,0.1)\n",
    "y = np.zeros(4*10)\n",
    "y[:10] = -0.5\n",
    "y[10:30] = 0.5\n",
    "y[30:] = -0.5\n",
    "y += np.random.randn(40)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(x,y)\n",
    "plt.scatter(x,y)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Time steps\", fontsize=fontsize)\n",
    "plt.ylabel(\"s\", fontsize=fontsize)\n",
    "plt.title(\"Bump data\", fontsize=fontsize)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bump data\n",
    "np.save(\"models/bump\", np.stack([x,y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a (very simple) neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bump(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n, m, hidden_dim):\n",
    "        super(Bump, self).__init__()\n",
    "        self.network = torch.nn.Sequential(torch.nn.Linear(n, hidden_dim),\n",
    "                                           torch.nn.ReLU(),\n",
    "                                           torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                                           torch.nn.ReLU(),\n",
    "                                           torch.nn.Linear(hidden_dim, m))\n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructing neural network.\n",
    "hidden_dim = 8\n",
    "\n",
    "# n=1 (time), m=1 y value\n",
    "# vanilla model to train with STL\n",
    "torch.manual_seed(0)\n",
    "bump = Bump(1, 1, hidden_dim)\n",
    "optimizer = torch.optim.Adam(bump.parameters(), lr=0.01, weight_decay=0.10)\n",
    "\n",
    "# model to train with STL\n",
    "torch.manual_seed(0)\n",
    "bump_stl = Bump(1, 1, hidden_dim)\n",
    "optimizer_stl = torch.optim.Adam(bump_stl.parameters(), lr=0.01, weight_decay=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1]) torch.Size([40, 1])\n"
     ]
    }
   ],
   "source": [
    "xx = torch.as_tensor(x).float().unsqueeze(-1)\n",
    "yy = torch.as_tensor(y).float().unsqueeze(-1)\n",
    "a = torch.as_tensor(0.48).float()\n",
    "b = torch.as_tensor(0.52).float()\n",
    "\n",
    "print(xx.shape,yy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating stl formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "◻ [10, 29]( (y_exp >= input) ∧ (y_exp <= input) )\n"
     ]
    }
   ],
   "source": [
    "y_exp = stlcg.Expression('y_exp', yy)\n",
    "ϕ1 = y_exp > a\n",
    "ϕ2 = y_exp < b\n",
    "ϕ = stlcg.Always(subformula=ϕ1 & ϕ2, interval=[10,29]) \n",
    "print(ϕ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training network without STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "0 loss = 0.730   mse = 0.730    robustness = -0.244\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n",
      "torch.Size([40, 1])\n",
      "torch.Size([1, 40, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4d85785f8fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mϕ_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.unsqueeze(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mϕ_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrobustness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mϕ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobustness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mϕ_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mϕ_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mγ\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrobustness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/src/stlcg.py\u001b[0m in \u001b[0;36mrobustness\u001b[0;34m(self, inputs, time, pscale, scale, keepdim, agm, distributed, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         '''\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/src/stlcg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(formula, inputs, pscale, scale, keepdim, agm, distributed, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobustness_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobustness_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_input_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not a invalid input trace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/src/stlcg.py\u001b[0m in \u001b[0;36mrobustness_trace\u001b[0;34m(self, inputs, pscale, scale, keepdim, agm, distributed, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrobustness_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# Compute the robustness trace of the subformula and that is the input to the temporal operator graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubformula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                              \u001b[0;31m# [batch_size, time_dim, ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/src/stlcg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(formula, inputs, pscale, scale, keepdim, agm, distributed, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobustness_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobustness_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_input_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not a invalid input trace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/src/stlcg.py\u001b[0m in \u001b[0;36mrobustness_trace\u001b[0;34m(self, inputs, pscale, scale, keepdim, agm, distributed, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrobustness_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparate_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubformula1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparate_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubformula2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m                                         \u001b[0;31m# [batch_size, time_dim, ...]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/src/stlcg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, scale, dim, keepdim, agm, distributed)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_true_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### hyperparameters #####\n",
    "γ = 0.0  # weighting on robustness loss\n",
    "###########################\n",
    "\n",
    "for _ in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = bump(xx)\n",
    "    print(y_pred.shape)\n",
    "    ϕ_input = y_pred.unsqueeze(0) #.unsqueeze(-1)\n",
    "    print(ϕ_input.shape)\n",
    "    robustness = ϕ.robustness((ϕ_input, ϕ_input), scale=-1)\n",
    "    mse = (y_pred - yy).pow(2).sum()\n",
    "    loss = mse + γ*torch.relu(-robustness).squeeze()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if (_ % 5000) == 0:\n",
    "        print(\"%i loss = %.3f   mse = %.3f    robustness = %.3f\"%(_, loss.detach().numpy(), mse.detach().numpy(), robustness.squeeze()))\n",
    "plt.plot(x +2, bump(xx).squeeze().detach())\n",
    "plt.plot(x + 2, yy.squeeze().detach())\n",
    "plt.plot([0,4],[a.numpy()]*2, 'k--', linewidth=1)\n",
    "plt.plot([0,4],[b.numpy()]*2, 'k--', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 0.0  # weighting on robustness loss\n",
    "PATH = \"models/bump_%.2f.model\"%γ\n",
    "np.save(\"models/bump_data_%.2f.npy\"%γ, torch.cat([xx, bump(xx)], dim=-1).detach().numpy())\n",
    "torch.save(bump.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training network with STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### hyperparameters #####\n",
    "γ = 2.  # weighting on robustness loss\n",
    "###########################\n",
    "\n",
    "for _ in range(2000):\n",
    "    optimizer_stl.zero_grad()\n",
    "    y_pred = bump_stl(xx)\n",
    "    ϕ_input = y_pred.unsqueeze(0) #.unsqueeze(-1)\n",
    "    robustness = ϕ.robustness((ϕ_input, ϕ_input), scale=-1)\n",
    "    mse = (y_pred - yy).pow(2).sum()\n",
    "    loss = mse + γ*torch.relu(-robustness).squeeze()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer_stl.step()\n",
    "    if (_ % 50) == 0:\n",
    "        print(\"%i loss = %.3f   mse = %.3f    robustness = %.3f\"%(_, loss.detach().numpy(), mse.detach().numpy(), robustness.squeeze()))\n",
    "plt.plot(x +2, bump_stl(xx).squeeze().detach())\n",
    "plt.plot(x + 2, yy.squeeze().detach())\n",
    "plt.plot([0,4],[a.numpy()]*2, 'k--', linewidth=1)\n",
    "plt.plot([0,4],[b.numpy()]*2, 'k--', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 2.  # weighting on robustness loss\n",
    "PATH = \"models/bump_%.2f.model\"%γ\n",
    "np.save(\"models/bump_data_%.2f.npy\"%γ, torch.cat([xx, bump_stl(xx)], dim=-1).detach().numpy())\n",
    "torch.save(bump_stl.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "a = 0.48\n",
    "b = 0.52\n",
    "\n",
    "\n",
    "bump_data = np.load(\"models/bump.npy\")\n",
    "x = bump_data[0,:] + 2\n",
    "y = bump_data[1,:]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "γ = 0.0  # weighting on robustness loss\n",
    "data = np.load(\"models/bump_data_%.2f.npy\"%γ).T\n",
    "xx = data[0,:] + 2\n",
    "yy = data[1,:]\n",
    "\n",
    "plt.plot(xx, yy, linewidth=4, label=\"Reconstruction\")\n",
    "plt.plot(x, y, linewidth=4, label=\"Data\", linestyle='--')\n",
    "plt.plot([0,4],[a]*2, 'k--', linewidth=1)\n",
    "plt.plot([0,4],[b]*2, 'k--', linewidth=1)\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.xlabel(\"Time [s]\", fontsize=fontsize)\n",
    "plt.ylabel(\"Signal\", fontsize=fontsize)\n",
    "plt.legend(fontsize=fontsize-4)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.title(\"Neural Network Only ($\\gamma$ = %.2f)\"%γ, fontsize=fontsize+8)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "γ = 2.0  # weighting on robustness loss\n",
    "data = np.load(\"models/bump_data_%.2f.npy\"%γ).T\n",
    "xx = data[0,:] + 2\n",
    "yy = data[1,:]\n",
    "\n",
    "plt.plot(xx, yy, linewidth=4, label=\"Reconstruction\")\n",
    "plt.plot(x, y, linewidth=4, label=\"Data\", linestyle='--')\n",
    "plt.plot([0,4],[a]*2, 'k--', linewidth=1)\n",
    "plt.plot([0,4],[b]*2, 'k--', linewidth=1)\n",
    "plt.ylim([-0.8, 0.8])\n",
    "plt.xlabel(\"Time [s]\", fontsize=fontsize)\n",
    "plt.ylabel(\"Signal\", fontsize=fontsize)\n",
    "plt.legend(fontsize=fontsize-4)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.title(\"Neural Network Only ($\\gamma$ = %.2f)\"%γ, fontsize=fontsize+8)\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent prediction example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "xx = np.arange(-2.5, 2, 0.1)\n",
    "N = 256\n",
    "x = np.stack([xx for i in range(N)])\n",
    "y = 0.5*np.tanh(x * (0.3 + np.random.rand(N,1)*2)) + np.random.randn(*x.shape)*0.05\n",
    "np.save(\"models/intent_train.npy\", np.stack([x, y], axis=-1))\n",
    "\n",
    "\n",
    "N = 16\n",
    "x = np.stack([xx for i in range(N)])\n",
    "y = 0.5*np.tanh(x * (0.3 + np.random.rand(N,1)*2)) + np.random.randn(*x.shape)*0.05\n",
    "np.save(\"models/intent_test.npy\", np.stack([x, y], axis=-1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x.T + 2.5, y.T, alpha=0.6, c='#1f77b4')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"Time steps\", fontsize=20)\n",
    "plt.ylabel(\"s\", fontsize=20)\n",
    "plt.title(\"Seq-to-seq dataset\", fontsize=26)\n",
    "plt.tight_layout()\n",
    "# plt.axis(\"equal\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "xx = np.arange(-2.5, 2, 0.1)\n",
    "N = 1\n",
    "x = np.stack([xx for i in range(N)])\n",
    "y = 0.5*np.tanh(x * (0.3 + np.random.rand(N,1)*2)) + np.random.randn(*x.shape)*0.05\n",
    "fontsize = 24\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(xx[:10] + 2.5, y[:,:10].T, c='black', linewidth=1, zorder=-1)\n",
    "plt.scatter(xx[:10] + 2.5, y[:,:10].T, c='forestgreen', linewidth=3)\n",
    "plt.grid()\n",
    "plt.title(\"Intent Prediction Set-up\", fontsize=fontsize+8)\n",
    "plt.xlim([-0.2, 5])\n",
    "plt.ylim([-1, 1.5])\n",
    "plt.xlabel(\"Time [s]\", fontsize=fontsize)\n",
    "plt.ylabel(\"Signal\", fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(xx[:20] + 2.5, y[:,:20].T, c='black', linewidth=1, zorder=-1)\n",
    "plt.scatter(xx[:10] + 2.5, y[:,:10].T, c='forestgreen', linewidth=3)\n",
    "plt.scatter(xx[10:20] + 2.5, y[:,10:20].T, c='deepskyblue', linewidth=3)\n",
    "plt.grid()\n",
    "plt.title(\"Intent Prediction Set-up\", fontsize=fontsize+8)\n",
    "plt.xlim([-0.2, 5])\n",
    "plt.ylim([-1, 1.5])\n",
    "plt.xlabel(\"Time [s]\", fontsize=fontsize)\n",
    "plt.ylabel(\"Signal\", fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the model and dataset function for training\n",
    "class PredictionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, fname, history_length=10, prediction_length=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = np.load(fname)\n",
    "        self.history_length = history_length\n",
    "        self.prediction_length = prediction_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx, :self.history_length, :]\n",
    "        y = self.data[idx, self.history_length:self.history_length+self.prediction_length, :]\n",
    "        return {'x': x, 'y': y}\n",
    "    \n",
    "class Encoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lstm_input_dim, lstm_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.network = torch.nn.LSTM(lstm_input_dim, lstm_dim, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lstm_input_dim, lstm_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.rnn_network = torch.nn.LSTM(lstm_input_dim, lstm_dim, batch_first=True)\n",
    "        self.proj_network = torch.nn.Linear(lstm_dim, lstm_input_dim)\n",
    "        self.h0 = torch.zeros([1,1,lstm_dim])\n",
    "    \n",
    "    def forward(self, x, rnn_state, ph):\n",
    "        bs = x.shape[0]\n",
    "        y_out = []\n",
    "        for t in range(ph):\n",
    "            output, rnn_state = self.rnn_network(x, rnn_state)\n",
    "            x = self.proj_network(output)\n",
    "            y_out.append(x)\n",
    "        return torch.cat(y_out, dim=1)\n",
    "    \n",
    "class Predict(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lstm_input_dim, lstm_dim):\n",
    "        super(Predict, self).__init__()\n",
    "        \n",
    "        self.enc = Encoder(lstm_input_dim, lstm_dim)\n",
    "        self.dec = Decoder(lstm_input_dim, lstm_dim)\n",
    "        \n",
    "    def forward(self, x, ph):\n",
    "        enc_out, rnn_state = self.enc(x)\n",
    "        return self.dec(self.dec.proj_network(enc_out[:,-1:,:]), rnn_state, ph)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model and training data\n",
    "\n",
    "hidden_dim = 4\n",
    "\n",
    "# n=1 (time), m=1 y value\n",
    "# vanilla model to train without STL\n",
    "torch.manual_seed(0)\n",
    "pred = Predict(1, hidden_dim)\n",
    "optimizer = torch.optim.Adam(pred.parameters(), lr=0.01, weight_decay=0)\n",
    "\n",
    "# model to train with STL\n",
    "torch.manual_seed(0)\n",
    "pred_stl = Predict(1, hidden_dim)\n",
    "optimizer_stl = torch.optim.Adam(pred_stl.parameters())\n",
    "\n",
    "\n",
    "dataset = PredictionDataset(\"models/intent_train.npy\")\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up STL formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = stlcg.Expression('yf', yy)\n",
    "ϕ2 = yf > torch.as_tensor(0.4).float()\n",
    "ϕ3 = yf < torch.as_tensor(0.6).float()\n",
    "ϕ = ϕ2 & ϕ3\n",
    "ψ = stlcg.Always(subformula=ϕ, interval=[0,5])   # feeding trajectory not in reversed, so this time interval is actually the end of the trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the network without STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 0.0     # weighting on robustness loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    for batch_idx, data_dict in enumerate(train_loader):\n",
    "        x = data_dict['x'].float()[:,:,1:]\n",
    "        y = data_dict['y'].float()[:,:,1:]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = pred(x, 35)\n",
    "        y_loss = y_pred[:,:10,:]\n",
    "\n",
    "        y_future = y_pred[:,-35:,:]\n",
    "\n",
    "        robustness = torch.relu(-ψ.robustness((y_future, y_future), scale=-1)).sum()\n",
    "        mse = (y_loss - y).pow(2).sum(-1).mean(1).mean()\n",
    "        loss = mse + γ*robustness\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    print(\"%i loss = %.3f   mse = %.3f    robustness = %.3f\"%(_, loss.detach().numpy(), mse.detach().numpy(), robustness.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/intent_%.2f.model\"%γ\n",
    "torch.save(pred.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the network with STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 0.1     # weighting on robustness loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    for batch_idx, data_dict in enumerate(train_loader):\n",
    "        x = data_dict['x'].float()[:,:,1:]\n",
    "        y = data_dict['y'].float()[:,:,1:]\n",
    "        optimizer_stl.zero_grad()\n",
    "        y_pred = pred_stl(x, 35)\n",
    "        y_loss = y_pred[:,:10,:]\n",
    "\n",
    "        y_future = y_pred[:,-35:,:]\n",
    "\n",
    "        robustness = torch.relu(-ψ.robustness((y_future, y_future), scale=-1)).sum()\n",
    "        mse = (y_loss - y).pow(2).sum(-1).mean(1).mean()\n",
    "        loss = mse + γ*robustness\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_stl.step()\n",
    "    print(\"%i loss = %.3f   mse = %.3f    robustness = %.3f\"%(_, loss.detach().numpy(), mse.detach().numpy(), robustness.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/intent_%.2f.model\"%γ\n",
    "torch.save(pred_stl.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PredictionDataset(\"models/intent_test.npy\")\n",
    "test_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "for batch_idx, data_dict in enumerate(test_loader):\n",
    "    x = data_dict['x'].float()[:,:,1:]\n",
    "    y = data_dict['y'].float()[:,:,1:]\n",
    "    break\n",
    "    \n",
    "xx = np.arange(-2.5, 2, 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Predict(1, 4)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "γ = 0.0\n",
    "PATH = \"models/intent_%.2f.model\"%γ\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "y_pred = model(x, 35)\n",
    "\n",
    "for idx in range(0,1):\n",
    "    x_history = xx[:10]\n",
    "    history = x.numpy()[idx,:,:]\n",
    "    plt.plot(x_history+2.5, history, c=\"forestgreen\", label=\"History\")\n",
    "    \n",
    "    x_future = xx[9:20]\n",
    "    future = y.numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"deepskyblue\", label=\"Future\")\n",
    "    \n",
    "    x_future = xx[9:]\n",
    "    future = y_pred.detach().numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"coral\", label=\"Prediction\")\n",
    "    \n",
    "    \n",
    "\n",
    "for idx in range(0,10):\n",
    "    x_history = xx[:10]\n",
    "    history = x.numpy()[idx,:,:]\n",
    "    plt.plot(x_history+2.5, history, c=\"forestgreen\")\n",
    "    \n",
    "    x_future = xx[9:20]\n",
    "    future = y.numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"deepskyblue\")\n",
    "    \n",
    "    x_future = xx[9:]\n",
    "    future = y_pred.detach().numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"coral\")\n",
    "\n",
    "plt.plot([0,4.5],[0.4, 0.4], 'k--')\n",
    "plt.plot([0,4.5],[0.6, 0.6], 'k--')\n",
    "plt.xlim([-2.5, 2])\n",
    "plt.xlim([-1, 1])\n",
    "plt.axis(\"equal\")\n",
    "plt.legend(loc=\"upper left\", fontsize=fontsize-4)\n",
    "plt.title(\"LSTM only ($\\gamma$=%.2f)\"%γ, fontsize=fontsize)\n",
    "plt.xlabel(\"Time steps\", fontsize=fontsize)\n",
    "plt.ylabel(\"s\", fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "γ = 0.1\n",
    "PATH = \"models/intent_%.2f.model\"%γ\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "y_pred = model(x, 35)\n",
    "\n",
    "for idx in range(0,1):\n",
    "    x_history = xx[:10]\n",
    "    history = x.numpy()[idx,:,:]\n",
    "    plt.plot(x_history+2.5, history, c=\"forestgreen\", label=\"History\")\n",
    "    \n",
    "    x_future = xx[9:20]\n",
    "    future = y.numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"deepskyblue\", label=\"Future\")\n",
    "    \n",
    "    x_future = xx[9:]\n",
    "    future = y_pred.detach().numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"coral\", label=\"Prediction\")\n",
    "    \n",
    "    \n",
    "\n",
    "for idx in range(0,10):\n",
    "    x_history = xx[:10]\n",
    "    history = x.numpy()[idx,:,:]\n",
    "    plt.plot(x_history+2.5, history, c=\"forestgreen\")\n",
    "    \n",
    "    x_future = xx[9:20]\n",
    "    future = y.numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"deepskyblue\")\n",
    "    \n",
    "    x_future = xx[9:]\n",
    "    future = y_pred.detach().numpy()[idx,:,:]\n",
    "    future = np.concatenate([history[-1:,:], future], axis=0)\n",
    "    plt.plot(x_future+2.5, future, c=\"coral\")\n",
    "\n",
    "plt.plot([0,4.5],[0.4, 0.4], 'k--')\n",
    "plt.plot([0,4.5],[0.6, 0.6], 'k--')\n",
    "plt.xlim([-2.5, 2])\n",
    "plt.xlim([-1, 1])\n",
    "plt.axis(\"equal\")\n",
    "plt.legend(loc=\"upper left\", fontsize=fontsize-4)\n",
    "plt.title(\"STL + LSTM ($\\gamma$=%.2f)\"%γ, fontsize=fontsize)\n",
    "plt.xlabel(\"Time steps\", fontsize=fontsize)\n",
    "plt.ylabel(\"s\", fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
