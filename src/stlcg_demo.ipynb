{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(0, 'src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2b18fb52ca0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstlcg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstlviz\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstlcg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExpression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_learning_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/coda1/p-mkemp6/0/salsalehi3/Organoid_Suhail/stlcg/src/stlcg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import stlcg\n",
    "import stlviz as viz\n",
    "from stlcg import Expression\n",
    "from utils import print_learning_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create traces from numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t = np.arange(-3, 3, 0.2, dtype=np.float32)\n",
    "x_np = 0.5 * np.exp(-t**2).reshape([1, t.shape[0], 1])\n",
    "w_np = (0.4*np.exp(-(t + 0.5)**2) + 0.2*np.exp(-(t - 3)**2)).reshape([1, t.shape[0], 1])\n",
    "\n",
    "x = torch.tensor(x_np, requires_grad=False)\n",
    "w = torch.tensor(w_np, requires_grad=False)\n",
    "c = torch.tensor(1.0, dtype=torch.float, requires_grad=True)\n",
    "d = torch.tensor(0.9, dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(t, x_np[0,:,0], \".-\", linewidth=3, markersize=15, label=\"x\")\n",
    "plt.plot(t, w_np[0,:,0], \".-\", linewidth=3, markersize=15, label=\"w\")\n",
    "plt.legend(fontsize=16)\n",
    "plt.title(\"Traces\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing STL formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One way to construct formulas is to explicitly call the constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϕ1 = stlcg.LessThan(lhs='x', val=c)\n",
    "ϕ2 = stlcg.GreaterThan(lhs='w', val=d)\n",
    "ϕ3 = stlcg.LessThan(lhs='w', val=d)\n",
    "ϕ = stlcg.Always(subformula=ϕ1)\n",
    "ψ = stlcg.Always(subformula=ϕ3)\n",
    "formula = stlcg.And(subformula1=ϕ, subformula2=ψ)\n",
    "print(formula)\n",
    "viz.make_stl_graph(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way (preferred way) is to use the math operators which have been overloaded\n",
    "#### (less than, greater than, equal, not, and, or)\n",
    "#### Still need to use the Always and Or constructors explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_exp = Expression('x', x)    # The first argument is the name of the variable, the second argument is the numerical value\n",
    "w_exp = Expression('w', w)\n",
    "c_exp = Expression('c', c)         # If the variable is a parameter of the STL, then input the actual value\n",
    "d_exp = Expression('d', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ϕ1 = x_exp <= c_exp\n",
    "ϕ2 = w_exp >= d_exp \n",
    "ϕ3 = w_exp <= d_exp\n",
    "ϕ = stlcg.Always(subformula=ϕ1)\n",
    "ψ = stlcg.Always(subformula=ϕ3)\n",
    "formula = stlcg.And(subformula1=ϕ, subformula2=ψ)\n",
    "print(formula)\n",
    "viz.make_stl_graph(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the formula\n",
    "### You need to feed in the necessary inputs. If the formula requires multiple inputs, it takes in a tuple of length 2 where each element in the tuple is the input to each subformula, in the order they are created. If the formula requires more than two inputs, then the tuple contains a tuple, eg. (x, (y, z)). The grouping of the input traces depend on how the formula was created.\n",
    "\n",
    "#### the inputs can be made up of tensors, or Expression objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula2 = ϕ2 & formula\n",
    "print(formula2)\n",
    "viz.make_stl_graph(formula2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any of the inputs will work\n",
    "inputs = (w, (x_exp, w_exp))\n",
    "# inputs = (w_exp, (x_exp, w_exp))\n",
    "# inputs = (w, (x, w))\n",
    "\n",
    "pscale = 1     # \"pscale\" is the scale used for evaluting predicates\n",
    "scale = -1     # \"scale\" is the scale used in the maxish/minish function. <0 defaults to the true min/max\n",
    "formula2(inputs, pscale=pscale, scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing grad functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_exp = Expression('x', x)\n",
    "w_exp = Expression('w', w)\n",
    "c_exp = Expression('c', c)\n",
    "d_exp = Expression('d', d)\n",
    "lt = x_exp <= c_exp\n",
    "gt = w_exp <= d_exp\n",
    "formula = stlcg.Always(subformula=lt)\n",
    "inputs = x\n",
    "var_dict = {'c': c}\n",
    "print(formula)\n",
    "viz.make_stl_graph(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = torch.optim.Adam(var_dict.values(), lr=learning_rate)\n",
    "scale = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(20000):\n",
    "    sc = scale + i/500\n",
    "    loss = formula.robustness(inputs, scale=sc).mean()**2 #+ 0.001*(c**2 + d**2)\n",
    "    if i % 500 == 0:\n",
    "        print_learning_progress(formula, inputs, var_dict, i, loss, sc)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        c -= learning_rate * c.grad\n",
    "        c.grad.zero_()\n",
    "#         d -= learning_rate * d.grad\n",
    "#         d.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:2020.02]",
   "language": "python",
   "name": "conda-env-2020.02-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
