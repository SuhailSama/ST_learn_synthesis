{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d05944a90982275c61c0162b8b7dedf19e76c3e"
   },
   "source": [
    "# Deep Clustering for Unsupervised Learning 0f Visual Features\n",
    "https://arxiv.org/pdf/1807.05520.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\suhai\\anaconda3\\envs\\mytorch\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\suhai\\anaconda3\\envs\\mytorch\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "210bb092f2f2017eb90652a628a4ab52edc734e7"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e12340cdb39826fb1c3d7e6ab5021fbcef214a82",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def show_cluster(cluster, labels, dataset, limit=32):\n",
    "    images = []\n",
    "    labels = np.array(labels)\n",
    "    indices = np.where(labels==cluster)[0]\n",
    "    \n",
    "    if not indices.size:\n",
    "        print(f'cluster: {cluster} is empty.')\n",
    "        return None\n",
    "    \n",
    "    for i in indices[:limit]:\n",
    "        image, _ = dataset[i]\n",
    "        images.append(image)\n",
    "        \n",
    "    gridded = make_grid(images)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.title(f'cluster: {cluster}')\n",
    "    plt.imshow(gridded.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "def show_neighbors(neighbors, dataset):\n",
    "    images = []\n",
    "    for n in neighbors:\n",
    "        images.append(dataset[n][0])\n",
    "\n",
    "    gridded = make_grid(images)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.title(f'image and nearest neighbors')\n",
    "    plt.imshow(gridded.permute(1, 2, 0))\n",
    "    \n",
    "    \n",
    "def extract_features(model, dataset, batch_size=32):\n",
    "    \"\"\"\n",
    "    Gets the output of a pytorch model given a dataset.\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    features = []\n",
    "    for image, _ in tqdm(loader, desc='extracting features'):\n",
    "        output = model(Variable(image).cuda())\n",
    "        features.append(output.data.cpu())\n",
    "    return torch.cat(features).numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a02f37287bffad0d0ed1f1e24c80d74fd18a30b3"
   },
   "source": [
    "## Dataset and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c43b1920f834b1b924c724b831335918ed6b210",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None, labels=[], limit=None):\n",
    "        self.root = Path(root)\n",
    "        self.image_paths = list(Path(root).glob('*/*.jpg'))\n",
    "        if limit:\n",
    "            self.image_paths = self.image_paths[:limit]\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        self.classes = set([path.parts[-2] for path in self.image_paths])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index] if self.labels else 0\n",
    "        image = Image.open(image_path)\n",
    "        if self.transforms:\n",
    "            return self.transforms(image), label\n",
    "        return image, label\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)    \n",
    "    \n",
    "transforms = T.Compose([T.Resize(224),\n",
    "                        T.CenterCrop(224),\n",
    "                        T.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4b8a131e69be1c196c910c9b9f09d6981e17810"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6fe25dca2797838544b04c45e32e8b9e0a562212",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# data\n",
    "path = r\"D:/Projects/ST_learn_synthesis/output/\"\n",
    "traj_raw_file       = path +case+ '_traj_raw.pkl'\n",
    "traj_input_par_file = path +case+ '_traj_input_par.pkl'\n",
    "\n",
    "root = '../input/images'\n",
    "limit_images = 10000\n",
    "\n",
    "# clustering\n",
    "pca_dim = 50\n",
    "kmeans_clusters = 100\n",
    "\n",
    "# convnet\n",
    "batch_size = 64\n",
    "num_classes = 100\n",
    "num_epochs = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e52b22d670ea18f6dcaddde8dedf8155275c0053"
   },
   "source": [
    "## Data\n",
    "Food Dataset, 101 different foods, 1000 samples each.\n",
    "\n",
    "We will use then first 10 classes to test this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9bf2874f385bb8ec11e936acd18569e2ba283e0d"
   },
   "outputs": [],
   "source": [
    "dataset = FoodDataset(root=root, limit=limit_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e9e7998e8a885fcb4854da93ebf4fbd99cf7d9f"
   },
   "outputs": [],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a87be606b70f0350c255caeff41896a99163acf"
   },
   "outputs": [],
   "source": [
    "image, _ = dataset[9000]\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d8f7b2b2b52c823f64eaace0839d45c62692617"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1c6eb4b829ab5e1eaba7101e67d6afb22b45bf1",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load resnet and alter last layer\n",
    "model = resnet18()\n",
    "model.fc = nn.Linear(512, num_classes)\n",
    "model.cuda();\n",
    "\n",
    "pca = IncrementalPCA(n_components=pca_dim, batch_size=512, whiten=True)\n",
    "kmeans = MiniBatchKMeans(n_clusters=kmeans_clusters, batch_size=512, init_size=3*kmeans_clusters)\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6baddc2c5131447801a1b51781a420acfbaa9142"
   },
   "source": [
    "# clustering loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "259ba1a788b17f42fbd2545cfaa420d20453fb0a",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cluster(pca, kmeans, model, dataset, batch_size, return_features=False):\n",
    "    features = extract_features(model, dataset, batch_size)  \n",
    "    reduced = pca.fit_transform(features)\n",
    "    pseudo_labels = list(kmeans.fit_predict(reduced))\n",
    "    if return_features:\n",
    "        return pseudo_labels, features\n",
    "    return pseudo_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8b6433ffc4d3dd66d9d459bee782aa21c303293"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "959aa392073410874f33caa17d349251c1ecf4cb",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_dataset, batch_size):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch, (images, labels) in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda().long()\n",
    "        out = model(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        total_loss += loss.data[0]\n",
    "        pbar.set_description(f'training - loss: {total_loss / (batch + 1)}')\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cdc9478cc215a08f6ca4fb94ad187e2eafc60df2"
   },
   "source": [
    "## Check how images are clustered with random convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36e24afd4c011e18b8b682ca7830ef86254c5f14",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_dataset = FoodDataset(root=root, transforms=transforms, limit=limit_images)\n",
    "pseudo_labels, features = cluster(pca, kmeans, model, raw_dataset, batch_size, return_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6a4eaca7a7702c7545a77176818b81bd16a90a0"
   },
   "source": [
    "### Cluster distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f10c0407c059d52b83901939c397a6f0bfd94100"
   },
   "outputs": [],
   "source": [
    "plt.hist(pseudo_labels, bins=kmeans_clusters)\n",
    "plt.title('cluster membership counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "518ce592c8323968ec37ba9393b0197c70074a2b"
   },
   "source": [
    "### largest clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "326478697ef70abf20e96efce78e23bbdf3371c3"
   },
   "outputs": [],
   "source": [
    "raw_dataset.classes ## all food types we have sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a2dee5e310862973bb1bb7eb0fdefa2caf3bd6cf"
   },
   "outputs": [],
   "source": [
    "counts = Counter(pseudo_labels)\n",
    "show_cluster(counts.most_common()[0][0], pseudo_labels, raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2be7b20c6f84badedc74749cc8fa21fa31c15b12"
   },
   "outputs": [],
   "source": [
    "show_cluster(counts.most_common()[1][0], pseudo_labels, raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2eb95fb61486bf57f7e60f1f01309437177fc3a8"
   },
   "source": [
    "## image retrieval on with random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b3dcfa87440cc23f30db11857d5884b369eee86"
   },
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a313247567f61edf559646a4d78fd0d876a8147c"
   },
   "outputs": [],
   "source": [
    "anchor_image = 0\n",
    "neighbors = knn.kneighbors([features[anchor_image]], n_neighbors=4, return_distance=False)[0]\n",
    "show_neighbors(neighbors, raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1215f55c97b6976f3188929b985562bbe6fae93"
   },
   "source": [
    "## Full Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "279b5377ffece1f1eff1e6b9902e5a526309f5f1"
   },
   "outputs": [],
   "source": [
    "for i in range(num_epochs):\n",
    "    pseudo_labels = cluster(pca, kmeans, model, raw_dataset, batch_size) # generate labels\n",
    "    labeled_dataset = FoodDataset(root=root, labels=pseudo_labels, transforms=transforms, limit=limit_images) # make new dataset with labels matched to images\n",
    "    train_epoch(model, optimizer, labeled_dataset, batch_size) # train for one epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9aebe374841c65db00e741b4250ac1c98b16049d"
   },
   "source": [
    "## Check new clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebcc4fb4cf87f4ac02fa9146e192ebd4fcb35280",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pseudo_labels, features = cluster(pca, kmeans, model, raw_dataset, batch_size, return_features=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "536b127738073719fd3b5ff7cc0348e437b8290b",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(pseudo_labels, bins=kmeans_clusters)\n",
    "plt.title('cluster membership counts');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e09f8f65e615db195b2404915fcdbe32114823c6",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "counts = Counter(pseudo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af8f35a53bd0747ba75168372d5b12a4b0c1e40c",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "show_cluster(counts.most_common()[0][0], pseudo_labels, raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bc6bc7aded4b1c0acb8d3d8181713d40b2b7acae",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "show_cluster(counts.most_common()[1][0], pseudo_labels, raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd0f6232696e6050b2f0ab13d975e1499c3c0670"
   },
   "source": [
    "## Image retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "515949b5e5326997885021847cfca129e2a43bdf",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4df9084b5923d6c2808bd6f9bfd125f67141253",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "anchor_image = 0\n",
    "neighbors = knn.kneighbors([features[anchor_image]], n_neighbors=4, return_distance=False)[0]\n",
    "show_neighbors(neighbors, raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e3d622e76751c569fa80b463349a810e27c82ba"
   },
   "source": [
    "## Train some more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da4d377f9ef61eabe6a0cdcc0fc998a5ba6e2e2f",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    pseudo_labels = cluster(pca, kmeans, model, raw_dataset, batch_size) # generate labels\n",
    "    labeled_dataset = FoodDataset(root=root, labels=pseudo_labels, transforms=transforms, limit=limit_images) # make new dataset with labels matched to images\n",
    "    train_epoch(model, optimizer, labeled_dataset, batch_size) # train for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cec45df70342314cbb52fd8227d68b02b4d3856",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "features = extract_features(model, raw_dataset, batch_size)  \n",
    "knn = NearestNeighbors(metric='cosine')\n",
    "knn.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa61418596d43eacbcb644132d7fe8340e651051",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "anchor_image = 0\n",
    "neighbors = knn.kneighbors([features[anchor_image]], n_neighbors=4, return_distance=False)[0]\n",
    "show_neighbors(neighbors, raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fbbd0296eb189e52f208095b9b8c7e2a4410520",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
