{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stone-hybrid",
   "metadata": {},
   "source": [
    "# Temporal Unsupervised learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greenhouse-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan  7 11:12:32 2021\n",
    "\n",
    "@author: suhail\n",
    "\"\"\"\n",
    "# loading/processing the images  \n",
    "import cv2\n",
    "from IPython.display import Video\n",
    "from keras.preprocessing.image import load_img \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.models import Model\n",
    "import pickle\n",
    "\n",
    "# clustering, dimension reduction, feature selection\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# learning classifiers\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from scipy.io import savemat\n",
    "\n",
    "# package for plotting dendograms \n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Projects\\NIH_Organoid\\Jup\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-planner",
   "metadata": {},
   "source": [
    "## Load models and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brave-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for feature extraction  \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "model = VGG16()\n",
    "CNN_model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "\n",
    "# import the spatial classifiers\n",
    "pkl_filename = 'spatial_classifiers_22k.pkl'\n",
    "SVM_model = pickle.load(open(pkl_filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-denmark",
   "metadata": {},
   "source": [
    "## Define the functions we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "purple-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file, CNN_model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "        # image_data_bw = img.max(axis=2)\n",
    "        # non_empty_columns = np.where(image_data_bw.max(axis=0)>0)[0]\n",
    "        # non_empty_rows = np.where(image_data_bw.max(axis=1)>0)[0]\n",
    "        # cropBox = (min(non_empty_rows), max(non_empty_rows), min(non_empty_columns), max(non_empty_columns))\n",
    "        # img_new = img[cropBox[0]:cropBox[1]+1, cropBox[2]:cropBox[3]+1 , :]\n",
    "        # new_image = img.fromarray(img_new)\n",
    "        # new_image.save('%s.png',file)\n",
    "        # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "        # img = np.mean(img, axis=2)\n",
    "        \n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = CNN_model.predict(imgx, use_multiprocessing=True)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "approximate-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_cluster(cluster):\n",
    "    plt.figure(figsize = (25,25));\n",
    "    # gets the list of filenames for a cluster\n",
    "    files = groups[cluster]\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 30:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 30\")\n",
    "        files = files[:29]\n",
    "    # plot each image in the cluster\n",
    "    for index, file in enumerate(files):\n",
    "        print(file)\n",
    "        plt.subplot(10,10,index+1);\n",
    "        img = load_img(file)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "def getList(dict): \n",
    "    return list(dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "optical-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nTreeClus(my_list, n = None, method = \"All\", ntree = 10, C = None):\n",
    "    \"\"\" nTreeClus is a clustering method by Mustafa Gokce Baydogan and Hadi Jahanshahi.\n",
    "    The method is suitable for clustering categorical time series (sequences). \n",
    "    You can always have access to the examples and description in \n",
    "    https://github.com/HadiJahanshahi/nTreeClus\n",
    "    If you have any question about the code, you may email hadijahanshahi [a t] gmail . com\n",
    "    \n",
    "    prerequisites:\n",
    "        numpy\n",
    "        pandas\n",
    "        sklearn\n",
    "        scipy\n",
    "    \n",
    "    Args:\n",
    "        my_list: a list of sequences to be clustered\n",
    "        n: \"the window length\" or \"n\" in nTreecluss, you may provide it or it will be\n",
    "            calculated automatically if no input has been suggested.\n",
    "        method: \n",
    "            DT: Decision Tree\n",
    "            RF: Random Forest\n",
    "            All: both methods\n",
    "        ntree: number of trees to be used in RF method. The defualt value is 10. \n",
    "             (Being too small has a bad effect on accuracy and being too large increases the complexity. \n",
    "              no less than 5 and no greater than 20.)\n",
    "        C: number of clusters if it is not provided, it will be calculated for 2 to 10.\n",
    "\n",
    "    Returns:\n",
    "        'C_DT': \"the optimal number of clusters with the aid of Decision Tree\",\n",
    "        'C_RF': \"the optimal number of clusters with the aid of Random Forest\",\n",
    "        'Parameter n': the parameter of the nTreeClus (n) - either calculated or manually given\n",
    "        'distance_DT': \"sparse disance between sequences with the aid of Decision Tree\",\n",
    "        'distance_RF': \"sparse disance between sequences with the aid of Random Forest\",\n",
    "        'labels_DT': \"labels based on the optimal number of clusters using DT\",\n",
    "        'labels_RF': \"labels based on the optimal number of clusters using RF\".\n",
    "            \n",
    "            NOTE: in order to convert the distance output to a square distance matrix, \n",
    "                \"scipy.spatial.distance.squareform\" should be used.\n",
    "                \n",
    "    ## simple example with the output\n",
    "    my_list = ['evidence','evident','provide','unconventional','convene']\n",
    "    nTreeClusModel = nTreeClus(my_list, method = \"All\")\n",
    "    # {'C_DT': 2,\n",
    "    # 'C_RF': 2,\n",
    "    # 'distance_DT': array([ 0.05508882,  0.43305329,  0.68551455,  0.43305329,  0.5       ,\n",
    "    #         0.7226499 ,  0.5       ,  0.86132495,  0.75      ,  0.4452998 ]),\n",
    "    # 'distance_RF': array([ 0.0809925 ,  0.56793679,  0.42158647,  0.57878823,  0.56917978,\n",
    "    #         0.47984351,  0.54545455,  0.55864167,  0.71278652,  0.3341997 ]),\n",
    "    # 'labels_DT': array([0, 0, 0, 1, 1]),\n",
    "    # 'labels_RF': array([0, 0, 0, 1, 1])}\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    ############# pre processisng #################\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    import scipy.spatial.distance as ssd\n",
    "    from scipy.cluster.hierarchy import linkage\n",
    "    from sklearn.metrics import silhouette_score \n",
    "    from scipy import cluster\n",
    "\n",
    "    \n",
    "    sequence_sep = pd.DataFrame(my_list) # create a DataFrame out of the given list\n",
    "    #sequence_sep = pd.DataFrame([list(x) for x in sequence[0]]) # separating the sequence\n",
    "    sequence_sep[sequence_sep.shape[1]] = None # adding an empty column to the end of sequence\n",
    "\n",
    "    if n is None:\n",
    "        min_length = min( map(len, my_list) )\n",
    "        total_avg = round(sum( map(len, my_list) ) / len(my_list)) # average length of strings\n",
    "        n = min (round(total_avg**0.5) + 1, min_length - 1)\n",
    "    \n",
    "    if (n < 3):\n",
    "        raise ValueError(\"Parameter n could not be less than 3. Remove the sequences with the length shorter than 3 and then re-run the function.\")\n",
    "    \n",
    "    \n",
    "    ############# matrix segmentation #################\n",
    "    firstiteration = 1\n",
    "    for i in range(len(my_list)):\n",
    "        for j in range(sequence_sep.shape[1]):\n",
    "            if (j < np.min(np.where(sequence_sep.iloc[i].isnull())) - n + 1): #check where is the position of the first \"None\"\n",
    "                if (firstiteration==1):\n",
    "                    seg_mat = pd.DataFrame(sequence_sep.iloc[i,j:j+n]).transpose()\n",
    "                    seg_mat['OriginalMAT_element'] = i\n",
    "                    seg_mat.columns = [np.arange(0,n+1)]\n",
    "                    firstiteration+=1\n",
    "                else:\n",
    "                    temp = pd.DataFrame(sequence_sep.iloc[i,j:j+n]).transpose()\n",
    "                    temp['OriginalMAT_element'] = i\n",
    "                    temp.columns = [np.arange(0,n+1)]\n",
    "                    seg_mat = seg_mat.append(temp)\n",
    "    seg_mat.columns = np.append(np.arange(0,n-1),('Class','OriginalMAT_element')) # renaming the column indexes\n",
    "    # dummy variable for DT and RF\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    seg_mat.loc[:,'Class'] = le.fit_transform(seg_mat.loc[:,'Class']) #make Y to numbers\n",
    "    #creating dummy columns for categorical data; one-hot encoding\n",
    "    seg_mat = pd.get_dummies(seg_mat).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    xtrain = seg_mat.drop(labels=['OriginalMAT_element','Class'],axis=1)\n",
    "    ytrain = seg_mat['Class']\n",
    "\n",
    "    ############# nTreeClus method using DT #################        \n",
    "    if (method == \"All\") or (method == \"DT\"):\n",
    "        dtree = DecisionTreeClassifier()\n",
    "        fitted_tree = dtree.fit(X=xtrain,y=ytrain)\n",
    "        predictiontree = dtree.predict(xtrain)\n",
    "        ### finding the terminal nodes.\n",
    "        terminal_tree = fitted_tree.tree_.apply(xtrain.values.astype('float32'))  #terminal output\n",
    "        terminal_output_tree  = pd.DataFrame(terminal_tree)\n",
    "        terminal_output_tree ['OriginalMAT_element'] = seg_mat['OriginalMAT_element'].values\n",
    "        #terminal_output_tree.drop(labels=0,axis=1,inplace=True)\n",
    "        terminal_output_tree.columns = ['ter','OriginalMAT_element']\n",
    "        terminal_output_tree_F = pd.crosstab(terminal_output_tree.OriginalMAT_element,terminal_output_tree.ter)\n",
    "        Dist_tree_terminal_cosine = ssd.pdist(terminal_output_tree_F,metric='cosine')\n",
    "        HC_tree_terminal_cosine = linkage(Dist_tree_terminal_cosine, 'ward')\n",
    "        #finding the number of clusters\n",
    "        if C is None:\n",
    "            max_clusters = min(11,len(my_list))\n",
    "            ress_sil = []\n",
    "            for i in range(2,max_clusters):\n",
    "                assignment_tree_terminal_cosine = cluster.hierarchy.cut_tree(HC_tree_terminal_cosine,i).ravel() #.ravel makes it 1D array.\n",
    "                ress_sil.append((silhouette_score(ssd.squareform(Dist_tree_terminal_cosine),assignment_tree_terminal_cosine,metric='cosine').round(3)*1000)/1000)\n",
    "            C = ress_sil.index(max(ress_sil)) + 2        \n",
    "        # assigning the correct label\n",
    "        optimal_cluster_tree = C\n",
    "        assignment_tree_terminal_cosine = cluster.hierarchy.cut_tree(HC_tree_terminal_cosine,C).ravel() #.ravel makes it 1D array.\n",
    "    \n",
    "        \n",
    "    ############# nTreeClus method using RF #################        \n",
    "    if (method == \"All\") or (method == \"RF\"):\n",
    "        np.random.seed(123)\n",
    "        forest = RandomForestClassifier(n_estimators= ntree ,max_features = 0.36)\n",
    "        fitted_forest = forest.fit(X=xtrain,y=ytrain)\n",
    "        predictionforest = forest.predict(xtrain)\n",
    "        ### Finding Terminal Nodes\n",
    "        terminal_forest = fitted_forest.apply(xtrain) #terminal nodes access\n",
    "        terminal_forest = pd.DataFrame(terminal_forest)\n",
    "        #Adding \"columnindex_\" to the beginning of all  \n",
    "        terminal_forest = terminal_forest.astype('str')\n",
    "        for col in terminal_forest:\n",
    "            terminal_forest[col] = '{}_'.format(col) + terminal_forest[col]\n",
    "        terminal_forest.head()\n",
    "        for i in range(terminal_forest.shape[1]):\n",
    "            if i == 0:\n",
    "                tempor = pd.concat( [seg_mat['OriginalMAT_element'] , terminal_forest[i]],ignore_index=True,axis=1)\n",
    "                rbind_terminal_forest = tempor\n",
    "            else:\n",
    "                tempor = pd.concat( [seg_mat['OriginalMAT_element'] , terminal_forest[i]],ignore_index=True,axis=1)\n",
    "                rbind_terminal_forest = pd.concat ([rbind_terminal_forest, tempor],ignore_index=True)\n",
    "\n",
    "        rbind_terminal_forest.columns = ['OriginalMAT_element','ter']\n",
    "        terminal_output_forest_F = pd.crosstab(rbind_terminal_forest.OriginalMAT_element,rbind_terminal_forest.ter)\n",
    "        Dist_RF_terminal_cosine = ssd.pdist(terminal_output_forest_F,metric='cosine')\n",
    "        HC_RF_terminal_cosine = linkage(Dist_RF_terminal_cosine, 'ward')\n",
    "        #finding the number of clusters\n",
    "        if C is None:\n",
    "            max_clusters = min(11,len(my_list))\n",
    "            ress_sil = []\n",
    "            for i in range(2,max_clusters):\n",
    "                assignment_RF_terminal_cosine = cluster.hierarchy.cut_tree(HC_RF_terminal_cosine,i).ravel() #.ravel makes it 1D array.\n",
    "                ress_sil.append((silhouette_score(ssd.squareform(Dist_RF_terminal_cosine),assignment_RF_terminal_cosine,metric='cosine').round(3)*1000)/1000)\n",
    "            C = ress_sil.index(max(ress_sil)) + 2        \n",
    "        # assigning the correct label\n",
    "        optimal_cluster_RF = C\n",
    "        assignment_RF_terminal_cosine = cluster.hierarchy.cut_tree(HC_RF_terminal_cosine,C).ravel() #.ravel makes it 1D array.\n",
    "\n",
    "    ############# output #################                \n",
    "    if (method == \"All\"):\n",
    "        return {\"distance_DT\":Dist_tree_terminal_cosine, \"labels_DT\":assignment_tree_terminal_cosine, \"C_DT\":optimal_cluster_tree, \"distance_RF\":Dist_RF_terminal_cosine, \"labels_RF\": assignment_RF_terminal_cosine, \"C_RF\":optimal_cluster_RF, \"Parameter n\":n}\n",
    "    elif (method == \"DT\"):\n",
    "        return {\"distance_DT\":Dist_tree_terminal_cosine, \"labels_DT\":assignment_tree_terminal_cosine, \"C_DT\":optimal_cluster_tree, \"Parameter n\":n}\n",
    "    else: \n",
    "        return {\"distance_RF\":Dist_RF_terminal_cosine, \"labels_RF\":assignment_RF_terminal_cosine, \"C_DT\":optimal_cluster_RF, \"Parameter n\":n}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-comparison",
   "metadata": {},
   "source": [
    "## Extract time series data from the simulations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "italic-character",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations/\"\\nos.chdir(rootdir)\\n\\nwith open(\\'traces.pkl\\', \\'rb\\') as pickle_load:\\n    my_list =pickle.load(pickle_load)\\n    \\nwith open(\\'names.pkl\\', \\'rb\\') as pickle_load:\\n    image_names =pickle.load(pickle_load)\\n# print the array\\nprint(len(my_list[3]))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment this cell for ready-to-use sample (don't forget to comment the next cell)\n",
    "\"\"\"\n",
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations/\"\n",
    "os.chdir(rootdir)\n",
    "\n",
    "with open('traces.pkl', 'rb') as pickle_load:\n",
    "    my_list =pickle.load(pickle_load)\n",
    "    \n",
    "with open('names.pkl', 'rb') as pickle_load:\n",
    "    image_names =pickle.load(pickle_load)\n",
    "# print the array\n",
    "print(len(my_list[3]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "respective-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trace(path, CNN_model,SVM_model):\n",
    "    # change the working directory to the path where the images are located\n",
    "    os.chdir(path)\n",
    "\n",
    "    # this list holds all the image filename\n",
    "    images = []\n",
    "    # creates a ScandirIterator aliased as files\n",
    "    with os.scandir(path) as files:\n",
    "      # loops through each file in the directory\n",
    "        for file in files:\n",
    "            if file.name.endswith('.png'): #or file.name.endswith('.jpg'):\n",
    "              # adds only the image files to the images list\n",
    "                images.append(file.name)\n",
    "              \n",
    "    dic_img = {}\n",
    "    p = r\"dump\"\n",
    "    traj_dist =[]\n",
    "    labels = []\n",
    "    # loop through each image in the dataset\n",
    "    only_class_labels = []\n",
    "    for image in sorted(images):\n",
    "        # try to extract the features and update the dictionary\n",
    "        image_name= os.path.splitext(image)[0]\n",
    "        try:\n",
    "            feat = extract_features(image,CNN_model)\n",
    "            label = SVM_model.predict(feat.reshape(1,-1))\n",
    "            arr = SVM_model.decision_function(feat.reshape(1,-1)).reshape(-1,1)\n",
    "            traj_dist.append(arr.tolist()) \n",
    "            labels.append(int(label[0]))\n",
    "            dic_img[image_name]= (labels,traj_dist,feat.tolist())\n",
    "        # if something fails, save the extracted features as a pickle file (optional)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            print('failed')\n",
    "            with open(p,'wb') as file:\n",
    "                pickle.dump(data,file)\n",
    "\n",
    "    # get a list of the filenames\n",
    "    filenames = np.array(list(dic_img.keys()))\n",
    "    \n",
    "    return filenames, labels,traj_dist, dic_img \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "paperback-belfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (1)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (10)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (100)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (101)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (102)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (103)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (104)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (105)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (106)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (107)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (108)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (109)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (11)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (110)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (111)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (112)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (113)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (114)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (115)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (116)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (117)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (118)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (119)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (12)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (120)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (121)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (122)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (123)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (124)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (125)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (126)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (127)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (128)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (129)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (13)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (130)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (131)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (132)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (133)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (134)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (135)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (136)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (137)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (138)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (139)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (14)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (140)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (141)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (142)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (143)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (144)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (145)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (146)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (147)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (148)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (149)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (15)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (150)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (151)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (152)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (153)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (154)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (155)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (156)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (157)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (158)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (159)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (16)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (160)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (161)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (162)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (163)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (164)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (165)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (166)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (167)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (168)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (169)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (17)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (170)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (171)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (172)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (173)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (174)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (175)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (176)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (177)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (178)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (179)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (18)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (180)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (181)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (182)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (183)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (184)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (185)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (186)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (187)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (188)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (189)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (19)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (190)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (191)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (192)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (193)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (194)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (195)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (196)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (197)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (198)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (199)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (2)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (20)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (200)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (201)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (202)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (203)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (204)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (205)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (206)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (207)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (208)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (209)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (21)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (210)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (211)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (212)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (213)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (214)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (215)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (216)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (217)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (218)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (219)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (22)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (220)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (221)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (222)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (223)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (224)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (225)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (226)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (227)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (228)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (229)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (23)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (230)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (231)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (232)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (233)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (234)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (235)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (236)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (237)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (238)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (239)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (24)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (240)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (241)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (242)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (243)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (244)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (245)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (246)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (247)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (248)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (249)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (250)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (251)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (252)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (253)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (254)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (255)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (256)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (257)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (258)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (259)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (26)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (260)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (261)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (262)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (263)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (264)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (265)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (266)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (267)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (268)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (269)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (27)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (270)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (271)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (272)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (273)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (274)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (275)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (276)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (277)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (278)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (279)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (28)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (280)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (281)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (282)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (283)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (284)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (285)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (286)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (287)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (288)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (289)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (29)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (290)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (291)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (292)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (293)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (294)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (295)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (296)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (297)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (298)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (299)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (3)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (30)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (300)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (301)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (302)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (303)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (304)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (305)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (306)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (307)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (308)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (309)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (31)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (310)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (311)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (312)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (313)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (314)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (315)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (316)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (317)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (318)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (319)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (32)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (320)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (321)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (322)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (323)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (324)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (325)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (326)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (327)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (328)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (329)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (33)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (330)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (331)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (332)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (333)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (334)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (335)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (336)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (337)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (338)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (339)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (34)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (340)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (341)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (342)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (343)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (344)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (345)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (346)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (347)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (348)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (349)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (35)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (350)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (351)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (352)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (353)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (354)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (355)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (356)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (357)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (358)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (359)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (36)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (360)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (361)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (362)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (363)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (364)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (365)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (366)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (367)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (368)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (369)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (37)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (370)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (371)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (372)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (373)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (374)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (375)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (376)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (377)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (378)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (379)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (38)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (380)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (381)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (382)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (383)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (384)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (385)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (386)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (387)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (388)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (389)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (39)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (390)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (391)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (392)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (393)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (394)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (395)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (396)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (397)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (398)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (399)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (4)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (40)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (401)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (402)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (403)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (404)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (405)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (406)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (407)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (408)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (409)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (41)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (410)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (411)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (412)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (413)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (414)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (415)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (416)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (417)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (418)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (419)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (42)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (420)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (421)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (422)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (423)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (424)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (425)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (426)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (427)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (428)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (429)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (43)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (430)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (431)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (432)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (433)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (434)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (435)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (436)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (437)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (438)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (439)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (44)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (440)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (441)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (442)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (443)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (444)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (445)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (446)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (447)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (448)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (449)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (45)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (450)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (451)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (452)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (453)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (454)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (455)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (456)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (457)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (458)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (459)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (46)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (460)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (461)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (462)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (463)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (47)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (48)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (49)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (5)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (50)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (51)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (52)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (53)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (54)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (55)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (56)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (57)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (58)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (59)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (6)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (60)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (61)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (62)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (63)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (64)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (65)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (66)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (67)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (68)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (69)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (7)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (70)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (71)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (72)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (73)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (74)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (75)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (76)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (77)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (78)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (79)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (8)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (80)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (81)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (82)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (83)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (84)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (85)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (86)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (87)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (88)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (89)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (9)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (90)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (91)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (92)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (93)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (94)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (95)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (96)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (97)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (98)\n",
      "F:/Projects/NIH_Organoid/Jup/simulations\\s (99)\n",
      "image_names 49\n",
      "labels_run_im 49\n",
      "traj_dist 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhai\\anaconda3\\envs\\organoid\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "#are you sure?\n",
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations\"\n",
    "\n",
    "traces=[]\n",
    "data_run={}\n",
    "image_names=[]\n",
    "labels_run_im = []\n",
    "run_names_full=[]\n",
    "run_names =[]\n",
    "traj_dist =[]\n",
    "counter =0\n",
    "for root, subdirs, files in os.walk(rootdir):\n",
    "    for run_name_full in sorted(subdirs):\n",
    "        path = os.path.join(root, run_name_full)\n",
    "        print(path)\n",
    "        run_name = ''.join(e for e in run_name_full if e.isalnum())\n",
    "        image_names_temp, labels_temp,traj_dist_temp,data_temp = extract_trace(path, CNN_model,SVM_model)\n",
    "        if len(labels_temp)>=49:\n",
    "            run_names.append(run_name)\n",
    "            run_names_full.append(run_name_full)\n",
    "            image_names.append(image_names_temp[:49])\n",
    "            labels_run_im.append(labels_temp[:49])  \n",
    "            traj_dist.append(traj_dist_temp[:49])     \n",
    "            data_run[run_name]= (run_name_full,image_names_temp[:49],labels_temp[:49],traj_dist_temp[:49],data_temp)\n",
    "            \n",
    "\n",
    "os.chdir(rootdir)\n",
    "print('image_names', len(image_names[0]))\n",
    "print('labels_run_im', len(labels_run_im[0]))\n",
    "print('traj_dist', len(traj_dist[0]))\n",
    "\n",
    "\n",
    "with open('run_names_full.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(run_names_full, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('image_names.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(image_names, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('labels_run_im.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(labels_run_im, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('traj_dist.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(traj_dist, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('data_run.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(data_run, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# save a copy for matlab use\n",
    "savemat('run_names_full.mat',{\"run_names_full\":run_names_full})\n",
    "savemat('image_names.mat',{\"image_names\":image_names})\n",
    "savemat('labels_run_im.mat',{\"labels_run_im\":labels_run_im})\n",
    "savemat('traj_dist.mat', {\"labels_run_im\":labels_run_im})\n",
    "savemat('data_run.mat', data_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "racial-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/images\"\n",
    "os.chdir(rootdir)\n",
    "pkl_filename = \"selected_features.pkl\"\n",
    "ind_selected_feat = pickle.load(open(pkl_filename, 'rb'))\n",
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations\"\n",
    "os.chdir(rootdir)\n",
    "feat_latest ={}\n",
    "feat_red ={}\n",
    "foot ={}\n",
    "for key1 in data_run.keys():\n",
    "    foot = data_run [key1][4]\n",
    "    feat_latest ={}\n",
    "    for index, key2 in enumerate(foot.keys()):\n",
    "        TEMPP = foot[key2] \n",
    "        feat_latest[key2] =np.array(TEMPP[2][0])[ind_selected_feat.astype(int)]\n",
    "    feat_red[key1]=feat_latest\n",
    "    \n",
    "savemat('all_feat_select.mat', feat_red)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "black-tuition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plot_00000': array([0.        , 0.60254174, 0.71538162, 0.        , 0.801202  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 4.28282213,\n",
       "        0.        , 3.15149641, 0.        , 2.9169383 , 0.        ,\n",
       "        0.        , 2.63220263, 0.54680598, 1.64621234, 0.        ]),\n",
       " 'plot_00050': array([0.49902859, 0.        , 1.34267497, 0.        , 2.69227552,\n",
       "        1.08625746, 0.49356878, 0.        , 0.        , 2.00433493,\n",
       "        0.        , 4.2838974 , 0.        , 2.75030994, 1.31952322,\n",
       "        0.        , 1.16086721, 0.        , 0.7991842 , 0.        ]),\n",
       " 'plot_00100': array([0.        , 0.        , 0.01559415, 0.        , 1.81920481,\n",
       "        0.21455809, 0.25929931, 0.        , 0.        , 2.39654207,\n",
       "        0.91862226, 3.82692027, 0.        , 3.52026749, 0.68943304,\n",
       "        0.        , 2.00538421, 0.23595974, 0.        , 0.        ]),\n",
       " 'plot_00150': array([0.        , 0.        , 0.        , 0.        , 1.56978321,\n",
       "        0.18685442, 0.01741904, 0.        , 0.        , 2.48840046,\n",
       "        0.72337425, 3.81413913, 0.        , 3.96291733, 0.94895494,\n",
       "        0.        , 2.16594887, 0.44488657, 0.        , 0.        ]),\n",
       " 'plot_00500': array([1.26187837, 1.52820587, 0.80986798, 0.        , 2.47361279,\n",
       "        0.57220471, 1.92945552, 0.        , 0.        , 1.24817157,\n",
       "        0.        , 4.70358324, 0.        , 4.39623833, 1.00548518,\n",
       "        0.        , 2.65404916, 0.        , 0.        , 0.        ]),\n",
       " 'plot_01000': array([1.07966495, 0.54542321, 2.01497626, 0.        , 1.90543032,\n",
       "        2.37872219, 3.23736501, 0.        , 0.        , 0.        ,\n",
       "        0.        , 3.70888662, 0.0363726 , 2.32551956, 0.        ,\n",
       "        0.        , 1.93144071, 0.        , 0.        , 0.        ]),\n",
       " 'plot_01500': array([1.93200564, 1.26230466, 1.76766729, 0.        , 1.96916842,\n",
       "        1.32457125, 2.66093874, 0.        , 0.        , 0.        ,\n",
       "        0.        , 3.05704188, 0.        , 2.94776773, 0.        ,\n",
       "        0.        , 2.44507599, 0.        , 0.        , 0.        ]),\n",
       " 'plot_02000': array([3.3743999 , 1.62788737, 2.02041006, 0.        , 1.7016542 ,\n",
       "        1.55709708, 2.38327646, 0.        , 0.        , 0.        ,\n",
       "        0.        , 3.25172925, 0.95421135, 4.60560894, 1.57866156,\n",
       "        0.        , 4.10469484, 0.        , 0.        , 0.        ]),\n",
       " 'plot_02500': array([2.08725166, 1.00755978, 2.258708  , 0.        , 1.87744737,\n",
       "        2.47144699, 3.04776549, 0.        , 0.        , 0.        ,\n",
       "        0.        , 3.82725596, 1.25209403, 4.57831097, 1.34880209,\n",
       "        0.        , 3.77194834, 0.15292704, 0.        , 0.        ]),\n",
       " 'plot_03000': array([3.49339247, 1.11787963, 1.72837341, 0.        , 0.72152394,\n",
       "        1.47287333, 3.0896318 , 0.        , 0.        , 0.04130359,\n",
       "        0.        , 4.037848  , 0.8131392 , 6.15476465, 2.45386171,\n",
       "        0.        , 4.49925375, 2.18077826, 0.        , 0.        ]),\n",
       " 'plot_03500': array([2.55773091, 7.78181696, 5.56930304, 0.        , 1.43373442,\n",
       "        0.        , 1.48680019, 0.        , 1.78594983, 0.15174654,\n",
       "        0.7919178 , 8.10042286, 1.83047354, 5.69785976, 4.61069012,\n",
       "        0.52254766, 5.9269104 , 3.49820828, 0.        , 0.        ]),\n",
       " 'plot_04000': array([5.78819036, 8.28339577, 2.6297195 , 0.        , 3.72430873,\n",
       "        0.        , 1.67522812, 0.        , 3.37581253, 1.14027476,\n",
       "        0.46305299, 6.33143282, 0.        , 3.56977654, 2.88852453,\n",
       "        1.84581304, 8.96479988, 2.61233974, 0.        , 0.        ]),\n",
       " 'plot_04500': array([6.94799328, 9.86349201, 7.33926105, 0.        , 2.54679561,\n",
       "        0.        , 2.24317765, 0.        , 1.64620364, 1.74893987,\n",
       "        0.        , 6.6167779 , 2.2499032 , 2.91131163, 4.2901001 ,\n",
       "        2.18263102, 7.40970802, 2.5735116 , 0.        , 0.        ]),\n",
       " 'plot_05000': array([ 7.04678965, 10.14822865,  7.73951864,  0.        ,  1.30621088,\n",
       "         0.        ,  3.31693411,  0.        ,  3.99837112,  0.35326892,\n",
       "         0.        ,  7.32061148,  2.57691431,  5.27307558,  5.09066963,\n",
       "         4.02099657,  7.92022181,  2.86478066,  0.        ,  0.32695737]),\n",
       " 'plot_05500': array([ 0.78452623,  5.13588572,  6.59837103,  0.        ,  5.96197271,\n",
       "         0.        ,  0.        ,  0.        ,  1.08257806,  0.        ,\n",
       "         0.        , 11.8937397 ,  4.95091963, 12.56484509,  7.43268728,\n",
       "         1.92918277, 11.66006279,  8.20566559,  0.        ,  0.        ]),\n",
       " 'plot_06000': array([ 1.25439239,  3.77557993,  7.56067276,  0.        ,  3.30820823,\n",
       "         0.        ,  2.16023731,  0.        ,  2.15991879,  2.39132214,\n",
       "         1.87644124,  8.60617447,  3.74853444, 10.08284473,  5.19210482,\n",
       "         0.12853348,  8.55421925,  7.66578865,  0.        ,  0.        ]),\n",
       " 'plot_06500': array([ 1.40387154,  4.51258707,  9.03190708,  0.        ,  3.26061487,\n",
       "         0.        ,  0.        ,  0.        ,  3.56962538,  1.96548164,\n",
       "         1.89077652, 10.31155968,  4.97675753, 11.18955994,  6.33422899,\n",
       "         0.86022514,  6.31126118,  7.4992609 ,  0.        ,  0.        ]),\n",
       " 'plot_07000': array([ 1.93791699,  5.79109192,  9.97814083,  0.        ,  2.62320089,\n",
       "         0.        ,  1.68462658,  0.        ,  4.48547554,  0.        ,\n",
       "         2.84420085, 10.48590755,  6.0456109 , 12.51608849,  6.87939501,\n",
       "         0.57476819,  5.95017195,  6.9396534 ,  0.        ,  0.        ]),\n",
       " 'plot_07500': array([ 2.94224453,  6.00606966, 12.40889168,  0.        ,  2.53713202,\n",
       "         0.        ,  0.        ,  0.        ,  6.28143692,  2.41866112,\n",
       "         4.23011446, 10.79210854,  7.09465218, 11.5190115 ,  7.85312033,\n",
       "         2.65527201,  6.5383606 ,  7.23106384,  0.        ,  0.        ]),\n",
       " 'plot_08000': array([ 1.31260443,  6.92124128, 14.21196938,  0.        ,  2.21767235,\n",
       "         0.        ,  0.        ,  0.        ,  8.15701008,  0.94525093,\n",
       "         5.86648512, 10.22494984,  8.68159485, 12.9825182 ,  6.35119867,\n",
       "         4.1898222 ,  7.76809835,  7.05838108,  0.        ,  0.        ]),\n",
       " 'plot_08500': array([ 2.54687333,  7.80546474, 17.48322868,  0.        ,  2.54255676,\n",
       "         0.        ,  0.        ,  0.        ,  8.49479198,  0.02182588,\n",
       "         8.62182999, 11.55813026,  7.68756294, 12.85761547,  6.49593544,\n",
       "         3.90639901,  7.55582142,  6.76038837,  0.        ,  0.        ]),\n",
       " 'plot_09000': array([ 1.04639864,  8.79432583, 14.80739975,  0.        ,  1.96974969,\n",
       "         0.        ,  1.15788901,  0.        ,  9.57711506,  0.56150895,\n",
       "         7.10670376, 11.9985323 ,  9.50084877, 11.44911671,  7.17225838,\n",
       "         4.07238102,  7.29944086,  8.50130272,  0.        ,  0.        ]),\n",
       " 'plot_09500': array([ 2.67096186,  9.00145817, 13.96355152,  0.        ,  3.56431174,\n",
       "         0.        ,  0.20924687,  0.        , 12.00102043,  0.        ,\n",
       "         9.27755356, 14.29075336,  8.41989136, 11.97207546,  7.1553669 ,\n",
       "         4.13229132, 10.9427681 ,  6.66950798,  0.        ,  0.        ]),\n",
       " 'plot_10000': array([ 2.47701001,  5.58018684, 13.53497314,  0.29352257,  1.76924133,\n",
       "         0.        ,  2.29541039,  0.        ,  9.23472691,  0.72688007,\n",
       "        11.78900909, 11.92854309,  4.15903664, 10.80631733,  3.22131777,\n",
       "         3.44583082, 12.03532028,  6.54394627,  0.        ,  0.        ]),\n",
       " 'plot_10500': array([ 2.91573811,  8.91944981, 13.55548573,  0.        ,  2.03354144,\n",
       "         0.        ,  4.30755663,  1.25420654,  8.41690063,  3.95467043,\n",
       "        16.02165794, 10.75982857,  1.99585748,  8.72908211,  3.40205145,\n",
       "         3.57761621, 13.55886745,  5.81361103,  0.        ,  0.        ]),\n",
       " 'plot_11000': array([ 0.        ,  4.89102554, 16.48326874,  1.32980919,  1.83859158,\n",
       "         0.43232223,  3.92811584,  0.        , 11.36305618,  6.46779299,\n",
       "        20.83116722, 12.77524853,  0.        ,  5.96842527,  0.34610659,\n",
       "         0.        , 18.41696548, 10.28407955,  0.        ,  2.54732084]),\n",
       " 'plot_11500': array([ 0.        ,  4.5472374 , 15.68203449,  2.75471354,  2.42230654,\n",
       "         1.25232756,  1.33345628,  2.91576791, 11.44221687,  5.33287621,\n",
       "        21.84322548, 11.90059566,  0.        ,  3.6052556 ,  0.        ,\n",
       "         0.76718146, 17.39367867,  9.11343956,  0.        ,  4.51336813]),\n",
       " 'plot_12000': array([ 1.03920281,  3.46139002, 18.17030525,  0.84490597,  0.        ,\n",
       "         0.        ,  2.12255669,  1.55180097, 13.55733299,  4.63589668,\n",
       "        23.43129539, 14.42054749,  0.        ,  4.56205559,  0.        ,\n",
       "         0.        , 20.7154274 , 11.41362381,  0.        ,  4.74337721]),\n",
       " 'plot_12500': array([ 1.66742396,  0.60656232, 15.85919857,  0.96879864,  2.51766348,\n",
       "         1.53618598,  0.09224218,  2.91695189, 12.41211605,  7.24764204,\n",
       "        23.09841537, 13.43034077,  0.        ,  3.78930283,  0.        ,\n",
       "         0.        , 20.43833351, 11.59576321,  0.        ,  6.34142637]),\n",
       " 'plot_13000': array([ 3.71749043,  4.60640097, 15.39019775,  1.94519186,  3.239784  ,\n",
       "         0.64529216,  0.11303991,  0.        , 15.05960083,  2.8021636 ,\n",
       "        22.08033752, 11.38408375,  0.        ,  4.50193167,  0.        ,\n",
       "         0.58185518, 20.58085442, 12.60102654,  0.        ,  8.98323822]),\n",
       " 'plot_13500': array([ 2.34464574,  4.92725897, 13.66657734,  2.87488675,  5.58806324,\n",
       "         4.26259661,  0.        ,  2.33958578, 11.02593803,  4.07728624,\n",
       "        23.71692848,  8.53957748,  0.        ,  3.07439852,  0.        ,\n",
       "         0.18792638, 17.47898674, 10.48450947,  0.        ,  5.17285395]),\n",
       " 'plot_14000': array([ 4.35111809,  4.88561153, 14.61382294,  2.11238456,  4.1349678 ,\n",
       "         5.39686632,  0.        ,  4.27128649, 10.4390316 ,  5.46211386,\n",
       "        22.75918961,  6.15132093,  0.        ,  2.68288469,  0.        ,\n",
       "         0.86755127, 16.05521584, 10.88239288,  0.        ,  4.60400486]),\n",
       " 'plot_14500': array([ 4.78326464,  2.37112832, 13.64429188,  2.35391808,  3.68912482,\n",
       "         4.36898375,  0.        ,  5.19118834,  9.48914909,  3.24376965,\n",
       "        19.85481262,  4.92511797,  0.        ,  4.84383917,  0.        ,\n",
       "         1.88965893, 14.27979851,  9.10506248,  0.        ,  5.5402298 ]),\n",
       " 'plot_15000': array([ 4.1739974 ,  3.58360243, 15.47614193,  1.87202799,  5.63980103,\n",
       "         3.26775122,  0.        ,  4.15225506, 11.62781811,  1.72974706,\n",
       "        18.83755493,  5.24120712,  0.        ,  5.20850754,  0.        ,\n",
       "         1.6903615 , 16.72022629,  9.92837906,  0.        ,  4.16625977]),\n",
       " 'plot_15500': array([ 4.69241953,  3.48205614, 15.86640644,  1.1882205 ,  6.26340723,\n",
       "         3.73197556,  0.        ,  1.72754359, 13.18415356,  3.45787668,\n",
       "        20.40992165,  6.28419495,  0.        ,  6.38357449,  0.        ,\n",
       "         0.58324945, 15.01759815,  7.93154716,  0.        ,  4.17365217]),\n",
       " 'plot_16000': array([ 3.32180548,  1.70037663, 14.3076849 ,  2.27379036,  4.24603319,\n",
       "         3.44619417,  0.        ,  4.28676462, 10.96601009,  2.80213928,\n",
       "        20.52950478,  3.72100997,  0.        ,  4.99670649,  0.        ,\n",
       "         1.18525362, 13.8588562 ,  7.33030987,  0.        ,  3.28630114]),\n",
       " 'plot_16500': array([ 4.50174093,  3.32508135, 15.14435101,  3.84384537,  4.59920311,\n",
       "         4.85859394,  0.        ,  3.12222338, 10.90875816,  2.14528036,\n",
       "        20.54040337,  3.04905558,  0.        ,  3.69581127,  0.        ,\n",
       "         2.45631933, 16.55379677,  7.88568687,  1.46813607,  5.88589954]),\n",
       " 'plot_17000': array([ 4.37098646,  3.40082645, 15.69111633,  0.27538621,  2.87940097,\n",
       "         3.84880877,  1.11393666,  0.62618184,  7.77793455,  4.60562992,\n",
       "        18.11918831,  4.73852825,  0.        ,  5.08968925,  0.        ,\n",
       "         0.95076573, 14.10327339,  8.85216999,  1.86752391,  0.11139715]),\n",
       " 'plot_17500': array([ 4.45461607,  1.45704484, 12.21970367,  1.01894844,  1.57759452,\n",
       "         4.45544004,  2.3702662 ,  0.10285029,  8.3127079 ,  2.57367373,\n",
       "        17.63922691,  3.64427352,  0.        ,  4.49778748,  0.        ,\n",
       "         1.17669761, 11.19492817,  8.16324806,  3.87221599,  0.        ]),\n",
       " 'plot_18000': array([ 5.37408638,  1.25482213, 13.20640945,  0.88503027,  0.75357687,\n",
       "         5.48671484,  4.22217894,  0.        , 10.20439148,  3.03223038,\n",
       "        14.22665405,  2.18604898,  0.        ,  4.50291586,  0.        ,\n",
       "         1.09043264, 11.39962673,  8.04750633,  5.32581997,  0.62286174]),\n",
       " 'plot_18500': array([ 4.39547539,  0.        , 11.41808319,  0.94580054,  0.88566399,\n",
       "         5.81356955,  3.88524818,  2.2240293 ,  8.21650028,  2.78629112,\n",
       "        14.65499973,  3.15146112,  0.        ,  4.65995169,  0.        ,\n",
       "         0.53744888, 11.18555832,  7.32187843,  6.00642061,  0.        ]),\n",
       " 'plot_19000': array([ 5.38351536,  0.46687531, 11.47382164,  0.71880269,  0.64802337,\n",
       "         5.42136145,  4.96256447,  0.        ,  9.95204544,  3.39970684,\n",
       "        13.22987461,  2.64823008,  0.        ,  5.27026987,  0.        ,\n",
       "         1.78947115, 11.40358353,  9.0074501 ,  5.67846918,  0.        ]),\n",
       " 'plot_19500': array([ 5.15863514,  0.48404285, 10.30824661,  0.        ,  0.60230774,\n",
       "         6.05358219,  4.78790188,  0.        ,  8.79759216,  2.32049465,\n",
       "        11.49005508,  1.70208848,  0.        ,  5.57812977,  0.        ,\n",
       "         1.39627838,  8.64489079,  7.11599445,  6.74144554,  0.        ]),\n",
       " 'plot_20000': array([ 6.39224911,  2.80401421, 11.0167017 ,  0.        ,  1.43161654,\n",
       "         5.61698389,  5.33149004,  0.        ,  7.55770445,  3.79008007,\n",
       "        11.88630772,  1.76475775,  0.        ,  3.75969744,  0.        ,\n",
       "         2.23071718,  8.08864594,  7.97263908,  8.21580982,  0.        ]),\n",
       " 'plot_20500': array([ 6.47930765,  2.03083563, 12.41202068,  1.14943445,  0.        ,\n",
       "         5.48840857,  5.45513964,  0.        ,  6.41494036,  4.04012108,\n",
       "        13.88104057,  3.90445471,  0.        ,  2.82231474,  0.        ,\n",
       "         0.        ,  9.99184513,  7.40586948,  6.34346581,  0.11464989]),\n",
       " 'plot_21000': array([ 6.24959469,  3.1766777 , 11.0131197 ,  0.        ,  1.8049624 ,\n",
       "         5.19581985,  4.12945604,  0.        ,  8.52769947,  2.07520914,\n",
       "        12.56018925,  2.28381157,  0.        ,  1.82117093,  0.        ,\n",
       "         0.        , 10.59515953,  7.21275806,  5.9570241 ,  1.22857356]),\n",
       " 'plot_21500': array([ 6.88069105,  3.36454105, 11.73801994,  0.        ,  0.49799594,\n",
       "         4.91943741,  4.50224257,  0.        ,  7.88990688,  3.45536757,\n",
       "        14.25599861,  4.7694459 ,  0.        ,  3.55926085,  0.        ,\n",
       "         0.        , 11.92174625,  9.1667614 ,  3.76735044,  0.        ]),\n",
       " 'plot_22000': array([ 5.43177986,  1.70933163, 10.34267426,  0.338851  ,  2.83041191,\n",
       "         5.11825848,  4.41334724,  0.        ,  9.49084282,  0.54068661,\n",
       "        13.62714481,  1.62891626,  0.        ,  2.18966675,  0.        ,\n",
       "         0.92461401, 11.75177383,  7.02431774,  7.23493958,  2.53735995]),\n",
       " 'plot_22500': array([ 5.77759409,  2.38973141,  9.87583637,  0.        ,  0.45495132,\n",
       "         5.39994574,  5.78454018,  0.        ,  6.86321306,  2.24975634,\n",
       "        11.43167973,  0.        ,  0.        ,  2.0354085 ,  0.        ,\n",
       "         0.        ,  9.38155556,  6.86943722,  5.46380663,  0.        ]),\n",
       " 'plot_23000': array([ 4.84404182,  2.05715275, 12.33415031,  0.02854905,  2.06282306,\n",
       "         5.02254057,  4.86252165,  0.        ,  8.23099422,  2.75743675,\n",
       "        13.96431541,  2.44061732,  0.        ,  1.12873554,  0.        ,\n",
       "         0.        , 10.19340324,  6.83525944,  5.91671705,  1.02576745]),\n",
       " 'plot_23500': array([ 6.63726759,  1.70999324, 10.13704967,  0.        ,  1.04468822,\n",
       "         5.51892567,  4.32916927,  0.        ,  6.81328344,  2.61268187,\n",
       "        12.36911869,  0.44958505,  0.        ,  2.7340951 ,  0.        ,\n",
       "         0.        ,  9.4543457 ,  7.61936569,  5.62110758,  0.        ]),\n",
       " 'plot_24000': array([ 5.24033594,  2.83164787, 11.06694126,  0.        ,  2.98325181,\n",
       "         5.51807499,  2.68338704,  0.        ,  8.08211613,  3.92625284,\n",
       "        11.87596321,  1.86663783,  0.        ,  2.42754793,  0.        ,\n",
       "         0.        ,  9.36968422,  7.13103485,  5.47788334,  0.38383788])}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_red[key1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations\"\n",
    "os.chdir(rootdir)\n",
    "pkl_filename = 'run_names_full.pkl'\n",
    "run_names_full = pickle.load(open(pkl_filename, 'rb'))\n",
    "pkl_filename = 'image_names.pkl'\n",
    "image_names = pickle.load(open(pkl_filename, 'rb'))\n",
    "pkl_filename = 'labels_run_im.pkl'\n",
    "labels_run_im = pickle.load(open(pkl_filename, 'rb'))\n",
    "pkl_filename = 'traj_dist.pkl'\n",
    "traj_dist = pickle.load(open(pkl_filename, 'rb'))\n",
    "pkl_filename = 'data_run.pkl'\n",
    "data_run = pickle.load(open(pkl_filename, 'rb'))\n",
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/images\"\n",
    "os.chdir(rootdir)\n",
    "pkl_filename = \"selected_features.pkl\"\n",
    "ind_selected_feat = pickle.load(open(pkl_filename, 'rb'))\n",
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations\"\n",
    "os.chdir(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "commercial-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/images\"\n",
    "os.chdir(rootdir)\n",
    "pkl_filename = \"selected_features.pkl\"\n",
    "ind_selected_feat = pickle.load(open(pkl_filename, 'rb'))\n",
    "ind_selected_feat\n",
    "savemat('ind_selected_feat.mat', {\"foo\":ind_selected_feat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  parallel compute [not finished]\n",
    "\"\"\"\n",
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations/\"\n",
    "\n",
    "def get_traces(root, subdirs, files):\n",
    "    traces={}\n",
    "    names ={}\n",
    "    data={}\n",
    "    my_list = []\n",
    "    image_names=[]\n",
    "    counter =0\n",
    "    for run_name in sorted(subdirs):\n",
    "        path = os.path.join(root, run_name)\n",
    "        print(path)\n",
    "        names[run_name], traces_temp,data[run_name] = extract_trace(path, CNN_model,SVM_model)\n",
    "        if traces_temp.shape >=(40,): \n",
    "            traces[run_name] = traces_temp            \n",
    "            my_list.append(traces_temp[:,4096].tolist())\n",
    "            image_names.append(run_name)\n",
    "            counter = counter +1 \n",
    "    return my_list       \n",
    "                \n",
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "my_list = [pool.apply(get_traces, args=(root, subdirs, files)) for root, subdirs, files in os.walk(rootdir)]\n",
    "pool.close()    \n",
    "os.chdir(rootdir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple example with the output \n",
    "nTreeClusModel = nTreeClus(labels_run_im, method = \"All\",ntree = 10, C=4)\n",
    "nTreeClusModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_tree_terminal_cosine = linkage(nTreeClusModel[\"distance_DT\"], 'ward')\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "dendrogram(HC_tree_terminal_cosine,labels=run_names, ax=ax)\n",
    "ax.tick_params(axis='x', which='major', labelsize=10)\n",
    "ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "HC_RF_terminal_cosine = linkage(nTreeClusModel[\"distance_RF\"], 'ward')\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "dendrogram(HC_RF_terminal_cosine,labels=run_names, ax=ax)\n",
    "ax.tick_params(axis='x', which='major', labelsize=10)\n",
    "ax.tick_params(axis='y', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_run=nTreeClusModel[\"labels_DT\"]\n",
    "all = list(zip(run_names,run_names_full,labels_run_im,traj_dist, labels_run))\n",
    "# print(len(all))\n",
    "# print(all[0])\n",
    "\n",
    "savemat('all_LTI.mat',dict(names =run_names, labels_run_im =labels_run_im,labels_run = labels_run, traj_dist =traj_dist ))\n",
    "savemat('all.mat', dict(all=all))\n",
    "with open('all_LTI.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(all, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#savemat('data_all.mat',data)\n",
    "#with open('name_trace_label.pkl', 'rb') as pickle_load:\n",
    "#    b =pickle.load(pickle_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDuplicatesWithCount(names,listOfLists):\n",
    "    ''' Get frequency count of duplicate elements in the given list '''\n",
    "    dictOfLists = dict()\n",
    "    dictOfFormulae = dict()\n",
    "    i=0\n",
    "    # Iterate over each element in list\n",
    "    for listOfElems in listOfLists:\n",
    "        dictOfElems = dict()\n",
    "        for elem in  listOfElems:\n",
    "        # If element exists in dict then increment its value else add it in dict\n",
    "            if elem in dictOfElems:\n",
    "                dictOfElems[elem] += 1\n",
    "            else:\n",
    "                dictOfElems[elem] = 1  \n",
    "    # Filter key-value pairs in dictionary. Keep pairs whose value is greater than 1 i.e. only duplicate elements from list.\n",
    "        dictOfElems = { key:value for key, value in dictOfElems.items() if value > 0}\n",
    "        time2=0\n",
    "        dictOfFormula = dict()\n",
    "        for key, value in dictOfElems.items():\n",
    "            time1= time2\n",
    "            time2=time1+500*value    \n",
    "            dictOfFormula[key] = time1,time2    \n",
    "        dictOfLists[names[i]] = dictOfElems\n",
    "        dictOfFormulae[names[i]]=dictOfFormula\n",
    "        i+=1\n",
    "    # Returns a dict of duplicate elements and thier frequency count\n",
    "    return dictOfLists,dictOfFormulae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictOfLists,dictOfFormulae=getDuplicatesWithCount(run_names,labels_run_im)\n",
    "\n",
    "#all_time_cls = list(zip(dictOfLists.keys,dictOfFormulae, labels))\n",
    "ex = run_names[100]\n",
    "print('for run with ID: ', ex)\n",
    "\n",
    "print(dictOfLists[ex])\n",
    "print(dictOfFormulae[ex])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDuplicatestime(names,listOfLists,time_cls):\n",
    "    ''' Get frequency count of duplicate elements all lists '''\n",
    "    dictOfLists = dict()\n",
    "    dictOfFormulae = dict()\n",
    "    dictOftimesteps = dict()\n",
    "    dictOftimecls =dict()\n",
    "    dictOftimecls_names =dict()\n",
    "\n",
    "    count =0\n",
    "    for j in range(3):\n",
    "        listOfnames=[]\n",
    "        for i in range(22):\n",
    "            dictOftimesteps[i*500] = []\n",
    "            # Iterate over all lists\n",
    "            count2= 0\n",
    "            for listOfElems in listOfLists:\n",
    "            # If element exists in dict then increment its value else add it in dict\n",
    "                if (time_cls[count2]==count) and (listOfElems[i] not in dictOftimesteps[i*500]):\n",
    "                    dictOftimesteps[i*500].append(int(listOfElems[i]))\n",
    "                if (time_cls[count2]==count) and (names[count2] not in listOfnames):\n",
    "                    listOfnames.append(names[count2])\n",
    "                count2+=1\n",
    "        dictOftimecls[count] = dict(dictOftimesteps)\n",
    "        dictOftimecls_names[count]= listOfnames\n",
    "        count+=1\n",
    "    # Returns a dict of duplicate elements and thier frequency count at each time \n",
    "    return dictOftimecls,dictOftimecls_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-formation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dictOftimes,dictOftimecls_names = getDuplicatestime(run_names,labels_run_im,labels_run)\n",
    "class_id =1\n",
    "print(dictOftimes[class_id])\n",
    "print(dictOftimecls_names[class_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_class(class_members):\n",
    "    plt.figure(figsize = (25,25));\n",
    "    # gets the list of filenames for a cluster\n",
    "    folders = class_members\n",
    "    \n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(folders) > 5:\n",
    "        print(f\"Clipping cluster size from {len(folders)} to 5\")\n",
    "        folders = folders[:5]\n",
    "    \n",
    "    for index, folder in enumerate(folders):\n",
    "        video_name = folder+'.avi'\n",
    "        images = [img for img in os.listdir(folder) if img.endswith(\".png\")]\n",
    "        image_last = os.path.join(folder, images[-1])\n",
    "        image_first = os.path.join(folder, images[0])\n",
    "        frame = cv2.imread(os.path.join(folder, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    "        \n",
    "        for image in sorted(images):\n",
    "            video.write(cv2.imread(os.path.join(folder, image)))\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "        Video(video_name)\n",
    "        print(image_last)\n",
    "        plt.subplot(10,10,index+1);\n",
    "        img = load_img(image_last)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "#         plt.subplot(10,10,5+index+1);\n",
    "#         img = load_img(image_first)\n",
    "#         img = np.array(img)\n",
    "#         plt.imshow(img)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_names_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations/\"\n",
    "os.chdir(rootdir)\n",
    "count =0\n",
    "num_cls = 3\n",
    "for i in range(num_cls):\n",
    "    Folders = dictOftimecls_names[i]\n",
    "    if len(Folders) > 2:\n",
    "            print(f\"Clipping cluster size from {len(Folders)} to 1\")\n",
    "            Folders = Folders[:1]\n",
    "    for folder_name in Folders:\n",
    "        for full_name in run_names_full:\n",
    "            if folder_name == ''.join(e for e in full_name if e.isalnum()):\n",
    "                image_folder = full_name\n",
    "                break\n",
    "\n",
    "        video_name = folder_name+'_'+str(i)+'.avi'\n",
    "\n",
    "        images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "        frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
    "\n",
    "        for image in sorted(images):\n",
    "            video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "\n",
    "        files = image_names[0]\n",
    "        files = files[[0,5,10,15,20,25,30,35]]\n",
    "        cwd = os.getcwd()\n",
    "        dir_name = full_name\n",
    "        for index, file in enumerate(files):\n",
    "            count =count+1\n",
    "            file_dir =  os.path.join(cwd,dir_name, files[index]+\".\"+'png' )\n",
    "#             print(file_dir)\n",
    "            plt.subplot(num_cls,9,count+1);\n",
    "            img = load_img(file_dir)\n",
    "            img = np.array(img)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do: \n",
    "# - show videos \n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "rootdir = r\"F:/Projects/NIH_Organoid/Jup/simulations/\"\n",
    "os.chdir(rootdir)\n",
    "for class_id in range(2):\n",
    "    print(dictOftimes[class_id])\n",
    "    view_class(dictOftimecls_names[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictOftimecls_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-charger",
   "metadata": {},
   "source": [
    "# Logical lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # To install pandas, `pip install pandas`\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn import preprocessing\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Data Science\n",
    "from traces import TimeSeries\n",
    "from traces import domain as Domain\n",
    "\n",
    "# Utilities Library\n",
    "import funcy as fn\n",
    "\n",
    "# Path utilities\n",
    "from pathlib import Path\n",
    "\n",
    "# Python STL library written for this project: github.com/mvcisback/py-stl\n",
    "import mtl\n",
    "# Parallelize The projections\n",
    "import multiprocessing\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine the files in the path\n",
    "path = r'F:\\Projects\\TLI\\Marcell\\LogicalLens-master\\example_data\\toy_car_speeds'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "data =[]\n",
    "def load_data(path):\n",
    "    speeds = pd.read_csv(path).Y\n",
    "    return list(zip(speeds.index, speeds))\n",
    "for filename in all_files:\n",
    "    df = load_data(filename)\n",
    "    data.append(df)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c bioconda fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW distance measure function\n",
    "def dtw_dist(x, y):\n",
    "    return fastdtw(x['Y'].sample(0.1), y['Y'].sample(0.1), dist=euclidean)[0]\n",
    "# PSTL \n",
    "def slow_down_lens(data):\n",
    "    def spec(params):\n",
    "        h, tau = params\n",
    "        tau *= 20\n",
    "        return all(speed < h for t, speed in data if t >= tau)\n",
    "    return spec\n",
    "\n",
    "# distances + \n",
    "def dist(x, y):\n",
    "    return np.linalg.norm(x - y)\n",
    "\n",
    "\n",
    "def val_to_vec(val):\n",
    "    return np.array([x for _, x in sorted(list(val.items()))])\n",
    "\n",
    "def project(x):\n",
    "    order = (\"a?\", \"tau?\")\n",
    "    ranges = {\"a?\": (-3, 3), \"tau?\": (10.0001, 1000)}\n",
    "    polarity = {\"a?\": False, \"tau?\": True} # Monotonically Increasing or Decreasing\n",
    "    return stl.lex_param_project(\n",
    "        phi, x, order=order, ranges=ranges, polarity=polarity)\n",
    "\n",
    "DISTS = np.vstack(list(map(lambda x: val_to_vec(project(x)), traces)))\n",
    "stl_sigma = np.var(DISTS, axis=0)\n",
    "stl_mu = np.mean(DISTS, axis=0)\n",
    "\n",
    "def stl_dist(x, y):\n",
    "    return dist(*map(lambda a: (val_to_vec(project(a)) - stl_mu)/stl_sigma, (x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the lens as class logicLens\n",
    "from logical_lens import LogicalLens\n",
    "lens = LogicalLens(n=2, lens=slow_down_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of rectangles\n",
    "recs = lens.boundary(data[0], approx=True, tol=1e-4) \n",
    "print(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Logical Distances.\n",
    "d = lens.dist(data[0], data[1])\n",
    "A = lens.adj_matrix(data=data)  # Compute full adjacency matrix.\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = squareform(np.array(A))\n",
    "linkage_matrix = linkage(dists,'ward')\n",
    "dendrogram(linkage_matrix, labels=[\"0\", \"1\", \"2\",\"3\"])\n",
    "plt.title(\"test\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [\n",
    "    (0, 1),   # Reference line intersecting origin and (0, 1)\n",
    "    (1, 0.3)  # ..                                     (1, 0.3)\n",
    "]\n",
    "f = lens.projector(points)  # Note, will project to -1 or 2 if no intersection\n",
    "                            # is found.\n",
    "Y = [f(d) for d in data]\n",
    "print(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Project onto 2 random lines.\n",
    "f2 = lens.random_projector(2)\n",
    "Y = [f2(d) for d in data]\n",
    "X = np.vstack([f2(d) for d in data])  # collect projected data into a matrix.\n",
    "print('X = ')\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw out data that had no intersections (and thus no slow downs).\n",
    "#intersects = (data != 2).X[0] * (data != 2).X[1]\n",
    "#X = X[intersects]\n",
    "\n",
    "# Learn a guassian mixture model\n",
    "model = GaussianMixture(4)\n",
    "model.fit(X)\n",
    "\n",
    "labels = np.array([model.predict(x.reshape(1,2))[0] for x in X])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np =np.array(X)\n",
    "print(X_np)\n",
    "plt.scatter(X_np[:,0],X_np[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-sunday",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref = data[3] # toy_data[0]\n",
    "#   dists = [lens.dist(ref, d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_downs = data  # data identified as slow downs\n",
    "\n",
    "f1 = lens.projector([(0.5, 1)])\n",
    "f2 = lens.projector([(1, 0.2)])\n",
    "X1 = np.vstack([f1(d) for d in slow_downs])\n",
    "X2 = np.vstack([f2(d) for d in slow_downs])\n",
    "\n",
    "box1 = X1.min(axis=0), X1.max(axis=0)  # (0.25, 0.55), (0.38, 0.76)\n",
    "box2 = X2.min(axis=0), X2.max(axis=0)  # (0.35, 0.17), (0.62, 0.31)\n",
    "print(box1)\n",
    "print(box2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-dryer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
